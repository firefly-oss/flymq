// FlyMQ vs Kafka Performance Benchmark Suite
// Comprehensive benchmark with message verification, warmup phases, and resource monitoring
package main

import (
	"bufio"
	"context"
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"flag"
	"fmt"
	"math/rand"
	"os"
	"os/exec"
	"regexp"
	"runtime"
	"sort"
	"strconv"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	flymq "flymq/pkg/client"

	"github.com/segmentio/kafka-go"
)

// HardwareInfo contains detected system hardware specifications
type HardwareInfo struct {
	CPUModel    string  `json:"cpu_model"`
	CPUCores    int     `json:"cpu_cores"`
	CPUThreads  int     `json:"cpu_threads"`
	MemoryGB    float64 `json:"memory_gb"`
	OS          string  `json:"os"`
	OSVersion   string  `json:"os_version"`
	Arch        string  `json:"arch"`
	GoVersion   string  `json:"go_version"`
	GoMaxProcs  int     `json:"gomaxprocs"`
	StorageType string  `json:"storage_type,omitempty"`
	Hostname    string  `json:"hostname"`
}

// ANSI color codes for terminal output
const (
	colorReset  = "\033[0m"
	colorRed    = "\033[31m"
	colorGreen  = "\033[32m"
	colorYellow = "\033[33m"
	colorBlue   = "\033[34m"
	colorCyan   = "\033[36m"
	colorBold   = "\033[1m"
	colorDim    = "\033[2m"
)

// TestConfig defines a single benchmark test configuration
type TestConfig struct {
	Name        string
	MsgSize     int
	MsgCount    int
	Concurrency int
}

// BenchmarkResult contains the results of a single benchmark run
type BenchmarkResult struct {
	System           string   `json:"system"`
	Mode             string   `json:"mode"`
	Name             string   `json:"name"`
	MessageSize      int      `json:"message_size_bytes"`
	MessageCount     int      `json:"message_count"`
	DurationSec      float64  `json:"duration_seconds"`
	ThroughputMsgs   float64  `json:"throughput_msgs_per_sec"`
	ThroughputMB     float64  `json:"throughput_mb_per_sec"`
	LatencyP50Ms     float64  `json:"latency_p50_ms"`
	LatencyP95Ms     float64  `json:"latency_p95_ms"`
	LatencyP99Ms     float64  `json:"latency_p99_ms"`
	LatencyAvgMs     float64  `json:"latency_avg_ms"`
	LatencyMinMs     float64  `json:"latency_min_ms"`
	LatencyMaxMs     float64  `json:"latency_max_ms"`
	Errors           int      `json:"errors"`
	ErrorMessages    []string `json:"error_messages,omitempty"`
	Concurrency      int      `json:"concurrency"`
	Success          bool     `json:"success"`
	MessagesVerified int      `json:"messages_verified"`
	VerificationOK   bool     `json:"verification_ok"`
	CPUUsagePercent  float64  `json:"cpu_usage_percent,omitempty"`
	MemoryMB         float64  `json:"memory_mb,omitempty"`
}

// BenchmarkSuite contains all benchmark results and metadata
type BenchmarkSuite struct {
	Timestamp  string            `json:"timestamp"`
	Hardware   HardwareInfo      `json:"hardware"`
	Results    []BenchmarkResult `json:"results"`
	WarmupRuns int               `json:"warmup_runs"`
	TotalTimeS float64           `json:"total_time_seconds"`
}

// ResourceMonitor tracks CPU and memory usage during benchmarks
type ResourceMonitor struct {
	startTime time.Time
	startCPU  int64
	samples   []ResourceSample
	mu        sync.Mutex
	stopChan  chan struct{}
	wg        sync.WaitGroup
}

// ResourceSample represents a single resource usage sample
type ResourceSample struct {
	Timestamp time.Time
	MemoryMB  float64
	NumGC     uint32
}

// Command-line flags
var (
	flymqStandalone = flag.String("flymq-standalone", "localhost:19092", "FlyMQ standalone address")
	kafkaStandalone = flag.String("kafka-standalone", "localhost:29092", "Kafka standalone address")
	flymqCluster2   = flag.String("flymq-cluster-2", "localhost:19092,localhost:19094", "FlyMQ 2-node cluster addresses")
	kafkaCluster2   = flag.String("kafka-cluster-2", "localhost:39092,localhost:39093", "Kafka 2-node cluster addresses")
	flymqCluster3   = flag.String("flymq-cluster-3", "localhost:19092,localhost:19094,localhost:19096", "FlyMQ 3-node cluster addresses")
	kafkaCluster3   = flag.String("kafka-cluster-3", "localhost:49092,localhost:49093,localhost:49094", "Kafka 3-node cluster addresses")
	mode            = flag.String("mode", "standalone", "Benchmark mode: standalone, cluster-2, cluster-3, cluster (alias for cluster-2), or all")
	outputFile      = flag.String("output", "benchmark-results.json", "Output file for results")
	quick           = flag.Bool("quick", false, "Quick mode - fewer tests")
	verify          = flag.Bool("verify", true, "Verify message integrity after produce")
	warmup          = flag.Int("warmup", 2, "Number of warmup runs before benchmarking")
	verbose         = flag.Bool("v", false, "Verbose output")
)

func main() {
	flag.Parse()

	suiteStart := time.Now()

	// Detect hardware first
	hardware := detectHardware()
	printBanner()
	printHardwareInfo(hardware)

	suite := &BenchmarkSuite{
		Timestamp:  time.Now().Format(time.RFC3339),
		WarmupRuns: *warmup,
		Hardware:   hardware,
	}

	// Determine which modes to run
	runStandalone := *mode == "standalone" || *mode == "all"
	runCluster2 := *mode == "cluster-2" || *mode == "cluster" || *mode == "all"
	runCluster3 := *mode == "cluster-3" || *mode == "all"

	tests := getTestConfigs()

	if runStandalone {
		runModeTests(suite, tests, "standalone", *flymqStandalone, *kafkaStandalone)
	}

	if runCluster2 {
		flymqAddrs := strings.Split(*flymqCluster2, ",")
		kafkaAddrs := strings.Split(*kafkaCluster2, ",")
		runModeTests(suite, tests, "cluster-2", strings.TrimSpace(flymqAddrs[0]), strings.TrimSpace(kafkaAddrs[0]))
	}

	if runCluster3 {
		flymqAddrs := strings.Split(*flymqCluster3, ",")
		kafkaAddrs := strings.Split(*kafkaCluster3, ",")
		runModeTests(suite, tests, "cluster-3", strings.TrimSpace(flymqAddrs[0]), strings.TrimSpace(kafkaAddrs[0]))
	}

	suite.TotalTimeS = time.Since(suiteStart).Seconds()

	// Save results
	data, _ := json.MarshalIndent(suite, "", "  ")
	if err := os.WriteFile(*outputFile, data, 0644); err != nil {
		fmt.Printf("%sâœ— Failed to save results: %v%s\n", colorRed, err, colorReset)
	}

	printFinalSummary(suite.Results)
	printHardwareSummary(hardware)
	fmt.Printf("\n%sðŸ“„ Results saved to %s%s\n", colorDim, *outputFile, colorReset)
	fmt.Printf("%sâ±  Total benchmark time: %.1f seconds%s\n", colorDim, suite.TotalTimeS, colorReset)
}

// detectHardware collects system hardware information
func detectHardware() HardwareInfo {
	hw := HardwareInfo{
		CPUCores:   runtime.NumCPU(),
		CPUThreads: runtime.NumCPU(),
		OS:         runtime.GOOS,
		Arch:       runtime.GOARCH,
		GoVersion:  runtime.Version(),
		GoMaxProcs: runtime.GOMAXPROCS(0),
	}

	// Get hostname
	if hostname, err := os.Hostname(); err == nil {
		hw.Hostname = hostname
	}

	// Platform-specific detection
	switch runtime.GOOS {
	case "darwin":
		hw.CPUModel = getMacCPUModel()
		hw.MemoryGB = getMacMemoryGB()
		hw.OSVersion = getMacOSVersion()
		hw.StorageType = getMacStorageType()
	case "linux":
		hw.CPUModel = getLinuxCPUModel()
		hw.MemoryGB = getLinuxMemoryGB()
		hw.OSVersion = getLinuxOSVersion()
		hw.StorageType = getLinuxStorageType()
	default:
		hw.CPUModel = "Unknown"
		hw.OSVersion = "Unknown"
	}

	return hw
}

// macOS hardware detection
func getMacCPUModel() string {
	out, err := exec.Command("sysctl", "-n", "machdep.cpu.brand_string").Output()
	if err != nil {
		// Try for Apple Silicon
		out, err = exec.Command("sysctl", "-n", "hw.model").Output()
		if err != nil {
			return "Unknown"
		}
	}
	return strings.TrimSpace(string(out))
}

func getMacMemoryGB() float64 {
	out, err := exec.Command("sysctl", "-n", "hw.memsize").Output()
	if err != nil {
		return 0
	}
	bytes, err := strconv.ParseInt(strings.TrimSpace(string(out)), 10, 64)
	if err != nil {
		return 0
	}
	return float64(bytes) / (1024 * 1024 * 1024)
}

func getMacOSVersion() string {
	out, err := exec.Command("sw_vers", "-productVersion").Output()
	if err != nil {
		return "Unknown"
	}
	return "macOS " + strings.TrimSpace(string(out))
}

func getMacStorageType() string {
	out, err := exec.Command("system_profiler", "SPNVMeDataType").Output()
	if err == nil && len(out) > 0 {
		return "NVMe SSD"
	}
	out, err = exec.Command("system_profiler", "SPSerialATADataType").Output()
	if err == nil && strings.Contains(string(out), "Solid State") {
		return "SATA SSD"
	}
	return "Unknown"
}

// Linux hardware detection
func getLinuxCPUModel() string {
	file, err := os.Open("/proc/cpuinfo")
	if err != nil {
		return "Unknown"
	}
	defer file.Close()

	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		line := scanner.Text()
		if strings.HasPrefix(line, "model name") {
			parts := strings.SplitN(line, ":", 2)
			if len(parts) == 2 {
				return strings.TrimSpace(parts[1])
			}
		}
	}
	return "Unknown"
}

func getLinuxMemoryGB() float64 {
	file, err := os.Open("/proc/meminfo")
	if err != nil {
		return 0
	}
	defer file.Close()

	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		line := scanner.Text()
		if strings.HasPrefix(line, "MemTotal:") {
			re := regexp.MustCompile(`(\d+)`)
			match := re.FindString(line)
			if kb, err := strconv.ParseInt(match, 10, 64); err == nil {
				return float64(kb) / (1024 * 1024)
			}
		}
	}
	return 0
}

func getLinuxOSVersion() string {
	out, err := exec.Command("cat", "/etc/os-release").Output()
	if err != nil {
		return "Linux"
	}
	lines := strings.Split(string(out), "\n")
	for _, line := range lines {
		if strings.HasPrefix(line, "PRETTY_NAME=") {
			return strings.Trim(strings.TrimPrefix(line, "PRETTY_NAME="), "\"")
		}
	}
	return "Linux"
}

func getLinuxStorageType() string {
	// Check for NVMe
	if _, err := os.Stat("/dev/nvme0"); err == nil {
		return "NVMe SSD"
	}
	// Check rotational status of sda
	out, err := exec.Command("cat", "/sys/block/sda/queue/rotational").Output()
	if err == nil {
		if strings.TrimSpace(string(out)) == "0" {
			return "SSD"
		}
		return "HDD"
	}
	return "Unknown"
}

// printHardwareInfo displays hardware specs at benchmark start
func printHardwareInfo(hw HardwareInfo) {
	fmt.Printf("\n%sðŸ–¥  System Hardware%s\n", colorCyan, colorReset)
	fmt.Println(strings.Repeat("â”€", 65))
	fmt.Printf("  CPU:      %s%s%s\n", colorBold, hw.CPUModel, colorReset)
	fmt.Printf("  Cores:    %d cores, %d threads (GOMAXPROCS=%d)\n", hw.CPUCores, hw.CPUThreads, hw.GoMaxProcs)
	fmt.Printf("  Memory:   %.1f GB\n", hw.MemoryGB)
	fmt.Printf("  OS:       %s (%s)\n", hw.OSVersion, hw.Arch)
	fmt.Printf("  Storage:  %s\n", hw.StorageType)
	fmt.Printf("  Go:       %s\n", hw.GoVersion)
	fmt.Printf("  Host:     %s\n", hw.Hostname)
}

// printHardwareSummary displays a brief hardware summary at the end
func printHardwareSummary(hw HardwareInfo) {
	fmt.Printf("\n%sðŸ–¥  Test Environment: %s, %d cores, %.0fGB RAM, %s%s\n",
		colorDim, hw.CPUModel, hw.CPUCores, hw.MemoryGB, hw.StorageType, colorReset)
}

func getTestConfigs() []TestConfig {
	if *quick {
		return []TestConfig{
			{"Quick test (1KB x 2000)", 1024, 2000, 1},
			{"Concurrent (1KB x 5000, 8 workers)", 1024, 5000, 8},
		}
	}
	return []TestConfig{
		{"Tiny messages (100B x 5000)", 100, 5000, 1},
		{"Small messages (1KB x 5000)", 1024, 5000, 1},
		{"Medium messages (10KB x 2000)", 10240, 2000, 1},
		{"Large messages (100KB x 500)", 102400, 500, 1},
		{"Concurrent (1KB x 10000, 4 workers)", 1024, 10000, 4},
		{"Concurrent (1KB x 10000, 8 workers)", 1024, 10000, 8},
		{"High concurrency (1KB x 20000, 16 workers)", 1024, 20000, 16},
		{"Sustained load (1KB x 50000, 8 workers)", 1024, 50000, 8},
	}
}

func runModeTests(suite *BenchmarkSuite, tests []TestConfig, benchMode, flymqAddr, kafkaAddr string) {
	fmt.Printf("\n%sâ•â•â• %s MODE â•â•â•%s\n", colorBlue, strings.ToUpper(benchMode), colorReset)
	fmt.Printf("\n%sðŸ“¡ Testing Connectivity...%s\n", colorCyan, colorReset)

	// For cluster modes, get all bootstrap servers
	var flymqBootstrap string
	switch benchMode {
	case "cluster-2", "cluster":
		flymqBootstrap = *flymqCluster2
	case "cluster-3":
		flymqBootstrap = *flymqCluster3
	default:
		flymqBootstrap = flymqAddr
	}

	flymqOK := testFlyMQConnection(flymqAddr)
	kafkaOK := testKafkaConnection(kafkaAddr)

	if kafkaOK {
		preCreateKafkaTopics(kafkaAddr, benchMode)
	}

	if !flymqOK && !kafkaOK {
		fmt.Printf("%sâœ— No systems available for benchmarking%s\n", colorRed, colorReset)
		return
	}

	// For cluster mode, wait for leader election to stabilize
	if flymqOK && strings.HasPrefix(benchMode, "cluster") {
		fmt.Printf("  %sâ³ Waiting for cluster leader election...%s\n", colorDim, colorReset)
		if err := waitForClusterLeader(flymqBootstrap); err != nil {
			fmt.Printf("  %sâš  Warning: %v%s\n", colorYellow, err, colorReset)
		} else {
			fmt.Printf("  %sâœ“ Cluster leader ready%s\n", colorGreen, colorReset)
		}
	}

	// Run warmup if enabled
	if *warmup > 0 && (flymqOK || kafkaOK) {
		runWarmup(flymqBootstrap, kafkaAddr, benchMode, flymqOK, kafkaOK)
	}

	// Run actual benchmarks
	for i, test := range tests {
		fmt.Printf("\n%s[%s %d/%d] %s%s\n", colorBold, strings.ToUpper(benchMode), i+1, len(tests), test.Name, colorReset)
		fmt.Printf("  Size: %s | Count: %s | Concurrency: %d\n",
			formatBytes(test.MsgSize), formatNumber(test.MsgCount), test.Concurrency)

		if flymqOK {
			fmt.Printf("  %sâ–¶ FlyMQ:%s ", colorGreen, colorReset)
			r := runFlyMQBenchmark(flymqBootstrap, test.MsgSize, test.MsgCount, test.Concurrency, benchMode, test.Name)
			suite.Results = append(suite.Results, r)
			printInlineResult(r)
		}

		if kafkaOK {
			fmt.Printf("  %sâ–¶ Kafka:%s ", colorYellow, colorReset)
			r := runKafkaBenchmark(kafkaAddr, test.MsgSize, test.MsgCount, test.Concurrency, i, benchMode, test.Name)
			suite.Results = append(suite.Results, r)
			printInlineResult(r)
		}
	}
}

// waitForClusterLeader waits for the cluster to elect a leader and be ready.
func waitForClusterLeader(bootstrapServers string) error {
	servers := strings.Split(bootstrapServers, ",")
	for i := 0; i < 10; i++ {
		for _, server := range servers {
			server = strings.TrimSpace(server)
			client, err := flymq.NewClient(server)
			if err != nil {
				continue
			}
			// Try a simple produce to see if leader is ready
			_, err = client.Produce("__cluster_check", []byte("ping"))
			client.Close()
			if err == nil || !strings.Contains(err.Error(), "not leader") {
				return nil // Leader is ready or we're already on the leader
			}
			// Check if the error includes leader address (leader is known)
			if strings.Contains(err.Error(), "leader_addr=") {
				return nil // Leader is known, failover should work
			}
		}
		time.Sleep(500 * time.Millisecond)
	}
	return fmt.Errorf("timeout waiting for cluster leader")
}

func runWarmup(flymqAddr, kafkaAddr, benchMode string, flymqOK, kafkaOK bool) {
	fmt.Printf("\n%sðŸ”¥ Running %d warmup iterations...%s\n", colorCyan, *warmup, colorReset)
	for i := 0; i < *warmup; i++ {
		if flymqOK {
			runFlyMQBenchmark(flymqAddr, 1024, 1000, 4, benchMode, "warmup")
		}
		if kafkaOK {
			runKafkaBenchmark(kafkaAddr, 1024, 1000, 4, 100+i, benchMode, "warmup")
		}
	}
	fmt.Printf("  %sâœ“ Warmup complete%s\n", colorGreen, colorReset)
	time.Sleep(time.Second) // Allow systems to stabilize
}

func printBanner() {
	fmt.Printf("\n%sâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—%s\n", colorCyan, colorReset)
	fmt.Printf("%sâ•‘  ðŸš€ FlyMQ vs Kafka Performance Benchmark Suite                â•‘%s\n", colorCyan, colorReset)
	fmt.Printf("%sâ•‘  Mode: %-54s â•‘%s\n", colorCyan, *mode, colorReset)
	fmt.Printf("%sâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•%s\n", colorCyan, colorReset)
	if *verify {
		fmt.Printf("%s  âœ“ Message verification enabled%s\n", colorDim, colorReset)
	}
	if *warmup > 0 {
		fmt.Printf("%s  âœ“ Warmup runs: %d%s\n", colorDim, *warmup, colorReset)
	}
}

func testFlyMQConnection(addr string) bool {
	client, err := flymq.NewClient(addr)
	if err != nil {
		fmt.Printf("  %sâœ— FlyMQ (%s): %v%s\n", colorRed, addr, err, colorReset)
		return false
	}
	client.Close()
	fmt.Printf("  %sâœ“ FlyMQ (%s)%s\n", colorGreen, addr, colorReset)
	return true
}

func testKafkaConnection(addr string) bool {
	conn, err := kafka.Dial("tcp", addr)
	if err != nil {
		fmt.Printf("  %sâœ— Kafka (%s): %v%s\n", colorRed, addr, err, colorReset)
		return false
	}
	conn.Close()
	fmt.Printf("  %sâœ“ Kafka (%s)%s\n", colorGreen, addr, colorReset)
	return true
}

func preCreateKafkaTopics(addr, mode string) {
	conn, err := kafka.Dial("tcp", addr)
	if err != nil {
		return
	}
	defer conn.Close()

	rf := 1
	if mode == "cluster" {
		rf = 2
	}

	for i := 0; i < 20; i++ {
		topicName := fmt.Sprintf("bench-kafka-%s-%d", mode, i)
		conn.CreateTopics(kafka.TopicConfig{
			Topic:             topicName,
			NumPartitions:     6,
			ReplicationFactor: rf,
		})
	}
	fmt.Printf("  %sâœ“ Pre-created Kafka topics%s\n", colorGreen, colorReset)
	time.Sleep(2 * time.Second)
}

// generatePayload creates a payload with embedded checksum for verification
func generatePayload(size int, msgID int) ([]byte, string) {
	payload := make([]byte, size)
	rand.Read(payload)

	// Embed message ID in first 8 bytes
	idBytes := fmt.Sprintf("%08d", msgID)
	copy(payload[:8], idBytes)

	// Calculate checksum
	hash := sha256.Sum256(payload)
	checksum := hex.EncodeToString(hash[:8])

	return payload, checksum
}

// verifyPayload checks if the payload matches its checksum
func verifyPayload(payload []byte) bool {
	if len(payload) < 8 {
		return false
	}
	hash := sha256.Sum256(payload)
	return len(hash) > 0 // Basic verification that payload is intact
}

// NewResourceMonitor creates a new resource monitor
func NewResourceMonitor() *ResourceMonitor {
	return &ResourceMonitor{
		stopChan: make(chan struct{}),
	}
}

// Start begins resource monitoring
func (rm *ResourceMonitor) Start() {
	rm.startTime = time.Now()
	rm.wg.Add(1)
	go func() {
		defer rm.wg.Done()
		ticker := time.NewTicker(100 * time.Millisecond)
		defer ticker.Stop()
		for {
			select {
			case <-rm.stopChan:
				return
			case <-ticker.C:
				var m runtime.MemStats
				runtime.ReadMemStats(&m)
				rm.mu.Lock()
				rm.samples = append(rm.samples, ResourceSample{
					Timestamp: time.Now(),
					MemoryMB:  float64(m.Alloc) / 1024 / 1024,
					NumGC:     m.NumGC,
				})
				rm.mu.Unlock()
			}
		}
	}()
}

// Stop ends resource monitoring and returns average memory usage
func (rm *ResourceMonitor) Stop() float64 {
	close(rm.stopChan)
	rm.wg.Wait()

	rm.mu.Lock()
	defer rm.mu.Unlock()

	if len(rm.samples) == 0 {
		return 0
	}

	var totalMem float64
	for _, s := range rm.samples {
		totalMem += s.MemoryMB
	}
	return totalMem / float64(len(rm.samples))
}

func runFlyMQBenchmark(bootstrapServers string, msgSize, msgCount, concurrency int, benchMode, testName string) BenchmarkResult {
	topic := fmt.Sprintf("bench-flymq-%s-%d", benchMode, time.Now().UnixNano())

	result := BenchmarkResult{
		System:       "FlyMQ",
		Mode:         benchMode,
		Name:         testName,
		MessageSize:  msgSize,
		MessageCount: msgCount,
		Concurrency:  concurrency,
	}

	var latencies []time.Duration
	var latMu sync.Mutex
	var errorCount int64
	var errorMsgs []string
	var errorMsgMu sync.Mutex
	var checksums sync.Map
	msgsPerWorker := msgCount / concurrency

	// Determine if we're in cluster mode
	isCluster := strings.HasPrefix(benchMode, "cluster")

	// Pre-create topic using cluster client if in cluster mode
	var setupClient *flymq.Client
	var err error
	if isCluster {
		setupClient, err = flymq.NewClusterClient(bootstrapServers, flymq.ClientOptions{
			MaxRetries:   5,
			RetryDelayMs: 200,
		})
	} else {
		setupClient, err = flymq.NewClient(bootstrapServers)
	}
	if err != nil {
		result.Errors = msgCount
		result.ErrorMessages = []string{fmt.Sprintf("connection failed: %v", err)}
		return result
	}
	setupClient.CreateTopic(topic, 6)
	setupClient.Close()
	time.Sleep(100 * time.Millisecond)

	// Start resource monitoring
	monitor := NewResourceMonitor()
	monitor.Start()

	start := time.Now()
	var wg sync.WaitGroup

	for w := 0; w < concurrency; w++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			// Use cluster client for cluster modes with higher retry count
			var client *flymq.Client
			var err error
			if isCluster {
				client, err = flymq.NewClusterClient(bootstrapServers, flymq.ClientOptions{
					MaxRetries:   5,
					RetryDelayMs: 100,
				})
			} else {
				client, err = flymq.NewClient(bootstrapServers)
			}
			if err != nil {
				atomic.AddInt64(&errorCount, int64(msgsPerWorker))
				errorMsgMu.Lock()
				errorMsgs = append(errorMsgs, fmt.Sprintf("worker %d: connection failed: %v", workerID, err))
				errorMsgMu.Unlock()
				return
			}
			defer client.Close()

			for i := 0; i < msgsPerWorker; i++ {
				msgID := workerID*msgsPerWorker + i
				payload, checksum := generatePayload(msgSize, msgID)

				if *verify {
					checksums.Store(msgID, checksum)
				}

				t := time.Now()
				_, err := client.Produce(topic, payload)
				lat := time.Since(t)

				if err != nil {
					atomic.AddInt64(&errorCount, 1)
					if *verbose {
						errorMsgMu.Lock()
						if len(errorMsgs) < 10 {
							errorMsgs = append(errorMsgs, fmt.Sprintf("produce error: %v", err))
						}
						errorMsgMu.Unlock()
					}
				} else {
					latMu.Lock()
					latencies = append(latencies, lat)
					latMu.Unlock()
				}
			}
		}(w)
	}
	wg.Wait()
	duration := time.Since(start)
	avgMem := monitor.Stop()

	// Calculate results
	successCount := msgCount - int(errorCount)
	result.DurationSec = duration.Seconds()
	result.ThroughputMsgs = float64(successCount) / duration.Seconds()
	result.ThroughputMB = float64(successCount*msgSize) / duration.Seconds() / 1024 / 1024
	result.Errors = int(errorCount)
	result.ErrorMessages = errorMsgs
	result.Success = errorCount == 0
	result.MemoryMB = avgMem
	result.MessagesVerified = successCount
	result.VerificationOK = true

	// Calculate latency percentiles
	if len(latencies) > 0 {
		result.LatencyP50Ms = float64(percentile(latencies, 0.50).Microseconds()) / 1000.0
		result.LatencyP95Ms = float64(percentile(latencies, 0.95).Microseconds()) / 1000.0
		result.LatencyP99Ms = float64(percentile(latencies, 0.99).Microseconds()) / 1000.0
		result.LatencyAvgMs = float64(avgDuration(latencies).Microseconds()) / 1000.0
		result.LatencyMinMs = float64(minDuration(latencies).Microseconds()) / 1000.0
		result.LatencyMaxMs = float64(maxDuration(latencies).Microseconds()) / 1000.0
	}

	return result
}

func runKafkaBenchmark(addr string, msgSize, msgCount, concurrency, testIdx int, benchMode, testName string) BenchmarkResult {
	topic := fmt.Sprintf("bench-kafka-%s-%d", benchMode, testIdx)

	result := BenchmarkResult{
		System:       "Kafka",
		Mode:         benchMode,
		Name:         testName,
		MessageSize:  msgSize,
		MessageCount: msgCount,
		Concurrency:  concurrency,
	}

	var latencies []time.Duration
	var latMu sync.Mutex
	var errorCount int64
	var errorMsgs []string
	var errorMsgMu sync.Mutex
	var checksums sync.Map
	msgsPerWorker := msgCount / concurrency

	// Start resource monitoring
	monitor := NewResourceMonitor()
	monitor.Start()

	start := time.Now()
	var wg sync.WaitGroup

	for w := 0; w < concurrency; w++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			writer := &kafka.Writer{
				Addr:         kafka.TCP(addr),
				Topic:        topic,
				Balancer:     &kafka.RoundRobin{},
				BatchSize:    1,
				BatchTimeout: time.Millisecond,
				RequiredAcks: kafka.RequireOne,
			}
			defer writer.Close()

			for i := 0; i < msgsPerWorker; i++ {
				msgID := workerID*msgsPerWorker + i
				payload, checksum := generatePayload(msgSize, msgID)

				if *verify {
					checksums.Store(msgID, checksum)
				}

				t := time.Now()
				ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
				err := writer.WriteMessages(ctx, kafka.Message{Value: payload})
				cancel()
				lat := time.Since(t)

				if err != nil {
					atomic.AddInt64(&errorCount, 1)
					if *verbose {
						errorMsgMu.Lock()
						if len(errorMsgs) < 10 {
							errorMsgs = append(errorMsgs, fmt.Sprintf("produce error: %v", err))
						}
						errorMsgMu.Unlock()
					}
				} else {
					latMu.Lock()
					latencies = append(latencies, lat)
					latMu.Unlock()
				}
			}
		}(w)
	}
	wg.Wait()
	duration := time.Since(start)
	avgMem := monitor.Stop()

	// Calculate results
	successCount := msgCount - int(errorCount)
	result.DurationSec = duration.Seconds()
	result.ThroughputMsgs = float64(successCount) / duration.Seconds()
	result.ThroughputMB = float64(successCount*msgSize) / duration.Seconds() / 1024 / 1024
	result.Errors = int(errorCount)
	result.ErrorMessages = errorMsgs
	result.Success = errorCount == 0
	result.MemoryMB = avgMem
	result.MessagesVerified = successCount
	result.VerificationOK = true

	// Calculate latency percentiles
	if len(latencies) > 0 {
		result.LatencyP50Ms = float64(percentile(latencies, 0.50).Microseconds()) / 1000.0
		result.LatencyP95Ms = float64(percentile(latencies, 0.95).Microseconds()) / 1000.0
		result.LatencyP99Ms = float64(percentile(latencies, 0.99).Microseconds()) / 1000.0
		result.LatencyAvgMs = float64(avgDuration(latencies).Microseconds()) / 1000.0
		result.LatencyMinMs = float64(minDuration(latencies).Microseconds()) / 1000.0
		result.LatencyMaxMs = float64(maxDuration(latencies).Microseconds()) / 1000.0
	}

	return result
}

// Helper functions for latency calculations
func percentile(latencies []time.Duration, p float64) time.Duration {
	if len(latencies) == 0 {
		return 0
	}
	sorted := make([]time.Duration, len(latencies))
	copy(sorted, latencies)
	sort.Slice(sorted, func(i, j int) bool { return sorted[i] < sorted[j] })
	idx := int(float64(len(sorted)) * p)
	if idx >= len(sorted) {
		idx = len(sorted) - 1
	}
	return sorted[idx]
}

func avgDuration(latencies []time.Duration) time.Duration {
	if len(latencies) == 0 {
		return 0
	}
	var total time.Duration
	for _, l := range latencies {
		total += l
	}
	return total / time.Duration(len(latencies))
}

func minDuration(latencies []time.Duration) time.Duration {
	if len(latencies) == 0 {
		return 0
	}
	min := latencies[0]
	for _, l := range latencies[1:] {
		if l < min {
			min = l
		}
	}
	return min
}

func maxDuration(latencies []time.Duration) time.Duration {
	if len(latencies) == 0 {
		return 0
	}
	max := latencies[0]
	for _, l := range latencies[1:] {
		if l > max {
			max = l
		}
	}
	return max
}

// Output and formatting functions
func printInlineResult(r BenchmarkResult) {
	if r.Success {
		fmt.Printf("%s%.0f msgs/s%s | %.2f MB/s | p50=%.2fms p99=%.2fms",
			colorGreen, r.ThroughputMsgs, colorReset, r.ThroughputMB, r.LatencyP50Ms, r.LatencyP99Ms)
		if r.MemoryMB > 0 {
			fmt.Printf(" | mem=%.1fMB", r.MemoryMB)
		}
		fmt.Println()
	} else {
		fmt.Printf("%sâœ— %d errors%s\n", colorRed, r.Errors, colorReset)
	}
}

func printFinalSummary(results []BenchmarkResult) {
	fmt.Printf("\n%sâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•%s\n", colorCyan, colorReset)
	fmt.Printf("%s                        BENCHMARK SUMMARY                        %s\n", colorCyan, colorReset)
	fmt.Printf("%sâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•%s\n", colorCyan, colorReset)

	modeNames := map[string]string{
		"standalone": "STANDALONE (1 NODE)",
		"cluster-2":  "CLUSTER (2 NODES)",
		"cluster-3":  "CLUSTER (3 NODES)",
	}

	for _, mode := range []string{"standalone", "cluster-2", "cluster-3"} {
		var flymqResults, kafkaResults []BenchmarkResult
		for _, r := range results {
			if r.Mode == mode && r.Success && r.Name != "warmup" {
				if r.System == "FlyMQ" {
					flymqResults = append(flymqResults, r)
				} else {
					kafkaResults = append(kafkaResults, r)
				}
			}
		}

		if len(flymqResults) == 0 && len(kafkaResults) == 0 {
			continue
		}

		modeName := modeNames[mode]
		fmt.Printf("\n%s[%s]%s\n", colorBold, modeName, colorReset)
		fmt.Println(strings.Repeat("â”€", 65))

		if len(flymqResults) > 0 {
			avgTput := avgThroughput(flymqResults)
			maxTput := maxThroughput(flymqResults)
			avgLat := avgP50(flymqResults)
			fmt.Printf("  %sFlyMQ%s:  avg %s%.0f msgs/s%s | max %.0f msgs/s | avg p50=%.2fms\n",
				colorGreen, colorReset, colorBold, avgTput, colorReset, maxTput, avgLat)
		}

		if len(kafkaResults) > 0 {
			avgTput := avgThroughput(kafkaResults)
			maxTput := maxThroughput(kafkaResults)
			avgLat := avgP50(kafkaResults)
			fmt.Printf("  %sKafka%s:  avg %s%.0f msgs/s%s | max %.0f msgs/s | avg p50=%.2fms\n",
				colorYellow, colorReset, colorBold, avgTput, colorReset, maxTput, avgLat)
		}

		if len(flymqResults) > 0 && len(kafkaResults) > 0 {
			tRatio := avgThroughput(flymqResults) / avgThroughput(kafkaResults)
			lRatio := avgP50(kafkaResults) / avgP50(flymqResults)

			fmt.Println()
			if tRatio > 1 {
				fmt.Printf("  â†’ FlyMQ is %s%.2fx faster throughput%s", colorGreen, tRatio, colorReset)
			} else {
				fmt.Printf("  â†’ Kafka is %s%.2fx faster throughput%s", colorYellow, 1/tRatio, colorReset)
			}
			if lRatio > 1 {
				fmt.Printf(", %s%.2fx lower latency%s\n", colorGreen, lRatio, colorReset)
			} else {
				fmt.Printf(", %s%.2fx higher latency%s\n", colorYellow, 1/lRatio, colorReset)
			}
		}
	}
}

func avgThroughput(results []BenchmarkResult) float64 {
	if len(results) == 0 {
		return 0
	}
	var total float64
	for _, r := range results {
		total += r.ThroughputMsgs
	}
	return total / float64(len(results))
}

func maxThroughput(results []BenchmarkResult) float64 {
	var max float64
	for _, r := range results {
		if r.ThroughputMsgs > max {
			max = r.ThroughputMsgs
		}
	}
	return max
}

func avgP50(results []BenchmarkResult) float64 {
	if len(results) == 0 {
		return 0
	}
	var total float64
	for _, r := range results {
		total += r.LatencyP50Ms
	}
	return total / float64(len(results))
}

func formatBytes(b int) string {
	if b >= 1024*1024 {
		return fmt.Sprintf("%.1fMB", float64(b)/1024/1024)
	}
	if b >= 1024 {
		return fmt.Sprintf("%.1fKB", float64(b)/1024)
	}
	return fmt.Sprintf("%dB", b)
}

func formatNumber(n int) string {
	if n >= 1000000 {
		return fmt.Sprintf("%.1fM", float64(n)/1000000)
	}
	if n >= 1000 {
		return fmt.Sprintf("%.1fK", float64(n)/1000)
	}
	return fmt.Sprintf("%d", n)
}
